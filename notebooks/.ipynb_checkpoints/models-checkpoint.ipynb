{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_name(df):\n",
    "    mrs = '|'.join(['Mrs\\.','Mme\\.', 'Ms\\.', 'Dr\\.', 'Lady\\.', 'Countess\\.'])    \n",
    "    mr = '|'.join(['Mr\\.','Don\\.','Rev\\.','Dr\\.', 'Major\\.', 'Sir\\.', 'Col\\.', 'Capt\\.', 'Jonkheer\\.'])\n",
    "    miss = '|'.join(['Miss\\.', 'Mlle\\.'])\n",
    "    return df.assign(Name = lambda x : x['Name'].str.replace('\\(.*\\)', '', regex=True),\n",
    "                     Mr =  lambda x : x['Name'].str.contains(mr).astype(int) ,\n",
    "                     Miss = lambda x : x['Name'].str.contains(miss).astype(int),\n",
    "                     Mrs = lambda x : x['Name'].str.contains(mrs).astype(int),\n",
    "                     Master = lambda x : (x['Name'].str.find('Master.') > -1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    df = (pd.read_csv(file, dtype = {\n",
    "                            \"PassengerId\":np.int32,\n",
    "                            \"Name\": \"object\",\n",
    "                            \"Pclass\":\"object\",\n",
    "                            \"Survived\":np.int32,\n",
    "                            \"Sex\":\"object\",\n",
    "                            \"Age\":np.float,\n",
    "                            \"SibSp\":\"object\",\n",
    "                            \"Embarked\":\"object\",\n",
    "                            \"Cabin\":\"object\",\n",
    "                            \"Fare\":np.float64,\n",
    "                        },)\n",
    "            .set_index(\"PassengerId\")\n",
    "            .pipe(onehot_name)\n",
    "            .drop(['Name','Ticket','Cabin'],axis=1)\n",
    "        )\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/train.csv\"\n",
    "data = read_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['age_cat'] = np.nan\n",
    "#data.apply(find_age_cat,axis=1).age_cat.str.contains('unknown').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['Survived'],axis=1) \n",
    "y_train = data.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['Age','Fare','Mr', 'Miss', 'Mrs', 'Master']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(random_state=0,initial_strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['Embarked', 'Sex', 'Pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent',missing_values=np.nan)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='error', drop=\"first\"))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_params(string0,string1,string2,string3=None):\n",
    "    params = []\n",
    "    if string3:\n",
    "        for el2 in string3[1]:\n",
    "            for el in string2[1]:\n",
    "                params.append({string1[0]:string1[1],\n",
    "                              string0[0]+'__'+string2[0]:[el],\n",
    "                              string0[1]+'__estimator__'+string2[0]:[el],\n",
    "                              string0[0]+'__'+string3[0]:[el2],\n",
    "                              string0[1]+'__estimator__'+string3[0]:[el2]})\n",
    "    else:\n",
    "        for el in string2[1]:\n",
    "            params.append({string1[0]:string1[1],\n",
    "                         string0[0]+'__'+string2[0]:[el],\n",
    "                         string0[1]+'__estimator__'+string2[0]:[el]})\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_feat = X_train.shape[1]\n",
    "\n",
    "#cross validation for inner and outer loopn in nested cv\n",
    "cv_outer = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_inner = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_sfs = StratifiedKFold(shuffle=True, random_state = rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RFR\n",
    "est = RandomForestClassifier(n_estimators=10,random_state=rs)\n",
    "sfs1 = SFS(estimator=est, \n",
    "           k_features=3,\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='neg_mean_absolute_error',\n",
    "           cv=cv_sfs)\n",
    "\n",
    "pipe_rfr_sfs = Pipeline([('pre_pros',  preprocessor),\n",
    "                 ('sfs', sfs1),\n",
    "                 ('rfc',est)])\n",
    "\n",
    "string1 = ['sfs__k_features', [(2,no_feat)]]\n",
    "string2 = ['n_estimators',list(range(1,15))]#[1,5,10,50,100,250,500,1000]]\n",
    "string3 = ['max_depth',list(range(1,10))]#[2,5,10,20,50,75,150]]\n",
    "param_grid_rfr_sfs = make_params(['rfc','sfs'],string1,string2,string3)\n",
    "\n",
    "gs_rf_sfs = GridSearchCV(estimator = pipe_rfr_sfs,\n",
    "                  param_grid = param_grid_rfr_sfs,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 126 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 630 out of 630 | elapsed: 26.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.17 s, sys: 268 ms, total: 9.44 s\n",
      "Wall time: 26min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pre_pros',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None...\n",
       "                         {'rfc__max_depth': [3], 'rfc__n_estimators': [1],\n",
       "                          'sfs__estimator__max_depth': [3],\n",
       "                          'sfs__estimator__n_estimators': [1],\n",
       "                          'sfs__k_features': [(2, 11)]},\n",
       "                         {'rfc__max_depth': [3], 'rfc__n_estimators': [2],\n",
       "                          'sfs__estimator__max_depth': [3],\n",
       "                          'sfs__estimator__n_estimators': [2],\n",
       "                          'sfs__k_features': [(2, 11)]}, ...],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_rf_sfs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score: 0.8451446864603603\n",
      "Best model params: {'rfc__max_depth': 9, 'rfc__n_estimators': 12, 'sfs__estimator__max_depth': 9, 'sfs__estimator__n_estimators': 12, 'sfs__k_features': (2, 11)}\n"
     ]
    }
   ],
   "source": [
    "get_gs_info(gs_rf_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gs_info(model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Best model score: ' + str(model.best_score_))\n",
    "    print('Best model params: '+ str(model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs_rf_sfs.best_estimator_.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: two_more.csv\n"
     ]
    }
   ],
   "source": [
    "submit(model,'two_more.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model,filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    X_test = read_data(\"../data/test.csv\")\n",
    "    predictions = model.predict(X_test)\n",
    "    submission = pd.DataFrame({'PassengerId':X_test.index,'Survived':predictions})\n",
    "    submission.to_csv(filename,index=False)\n",
    "    print('Saved file: ' + filename)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 4.17 s, total: 4min 38s\n",
      "Wall time: 19min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pre_pros',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None...\n",
       "                         {'rfc__max_depth': [20], 'rfc__n_estimators': [100],\n",
       "                          'sfs__estimator__max_depth': [20],\n",
       "                          'sfs__estimator__n_estimators': [100],\n",
       "                          'sfs__k_features': [(2, 11)]},\n",
       "                         {'rfc__max_depth': [20], 'rfc__n_estimators': [250],\n",
       "                          'sfs__estimator__max_depth': [20],\n",
       "                          'sfs__estimator__n_estimators': [250],\n",
       "                          'sfs__k_features': [(2, 11)]}, ...],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_rf_sfs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858602724248321"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_sfs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe rfr\n",
    "pipe_rfr = Pipeline([(\"pre_pros\",preprocessor), \n",
    "                     (\"rfr\",RandomForestClassifier(n_estimators=10,random_state=rs)) ])\n",
    "params_rfr = {\"rfr__n_estimators\":[1,5,10,50,100,250,500,1000],\n",
    "              \"rfr__max_depth\":[2,5,10,20,50,75,150]}\n",
    "\n",
    "#pipe lr\n",
    "pipe_lr = Pipeline([('pre_pros',preprocessor),\n",
    "                     ('pca',PCA()),\n",
    "                     ('lr',LogisticRegression(random_state=rs))])\n",
    "params_lr = {'pca__n_components':[1,3,5],\n",
    "             'lr__C':[0.0001,0.001,0.1,1,10,100,1000]}\n",
    "\n",
    "#cross validation for inner and outer loopn in nested cv\n",
    "cv_outer = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_inner = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_sfs = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "\n",
    "# grid-search\n",
    "gs_rf = GridSearchCV(estimator = pipe_rfr,\n",
    "                  param_grid = params_rfr,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr,\n",
    "                  param_grid = params_lr,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dumb baseline 61.62%\n",
      "Accuracy for baseline 78.68%\n"
     ]
    }
   ],
   "source": [
    "# Dumb baseline\n",
    "avg_dumb_baseline = np.ones((y_train.shape))*np.rint(y_train.astype(int).mean())\n",
    "acc_dumb_baseline = (y_train==avg_dumb_baseline).sum()/len(y_train)\n",
    "\n",
    "#smarter baseline - women survives and men dies\n",
    "baseline_pred = X_train.Sex.map({'female':1,'male':0})\n",
    "acc_baseline = (y_train==baseline_pred).sum()/len(y_train)\n",
    "\n",
    "#print\n",
    "print(f'Accuracy for dumb baseline {acc_dumb_baseline*100:.2f}%')\n",
    "print(f'Accuracy for baseline {acc_baseline*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nested cross validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 26s, sys: 10.8 s, total: 12min 37s\n",
      "Wall time: 12min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nested_score_rfr = cross_val_score(gs_rf,X_train,y_train,\n",
    "                                 cv=cv_outer,\n",
    "                                 scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80446927, 0.83707865, 0.7752809 , 0.8258427 , 0.86516854])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score_rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 229 ms, total: 2.91 s\n",
      "Wall time: 41min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nested_score_lr = cross_val_score(gs_lr,X_train,y_train,\n",
    "                                 cv=cv_outer,\n",
    "                                 scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80446927, 0.78651685, 0.79213483, 0.76404494, 0.79775281])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe lr\n",
    "pipe_lr_k = Pipeline([('pre_pros',preprocessor),\n",
    "                     ('inc_spac',PolynomialFeatures()),\n",
    "                     ('pca',PCA()),\n",
    "                     ('lr',LogisticRegression(random_state=rs))])\n",
    "params_lr_k = {\n",
    "             'inc_spac__degree':[1,2,5,10],\n",
    "             'pca__n_components':[1,3,5],\n",
    "             'lr__C':[0.0001,0.001,0.1,1,10,100,1000]}\n",
    "\n",
    "#cross validation for inner and outer loopn in nested cv\n",
    "cv_outer = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_inner = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "\n",
    "# grid-search\n",
    "\n",
    "\n",
    "gs_lr_k = GridSearchCV(estimator = pipe_lr_k,\n",
    "                  param_grid = params_lr_k,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nested_score_lr_k = cross_val_score(gs_lr_k,X_train,y_train,\n",
    "                                    cv=cv_outer,\n",
    "                                    scoring='accuracy',\n",
    "                                    verbose=2,\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pre_pros',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None...\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=1,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'lr__C': [0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
       "                         'pca__n_components': [1, 3, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumbission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = read_data(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Mr',\n",
       "       'Miss', 'Mrs', 'Master'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Mr',\n",
       "       'Miss', 'Mrs', 'Master'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gs_rf_sfs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction_baseline = X_test.Sex.map({'female':1,'male':0})\n",
    "baseline_sub = pd.DataFrame({'PassengerId':X_test.index,'Survived':prediction_baseline})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':X_test.index,'Survived':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: rf_sfs_sub.csv\n"
     ]
    }
   ],
   "source": [
    "filename = 'rf_sfs_sub.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_titanic]",
   "language": "python",
   "name": "conda-env-kaggle_titanic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
