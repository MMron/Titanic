{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_name(df):\n",
    "    mrs = '|'.join(['Mrs\\.','Mme\\.', 'Ms\\.', 'Dr\\.', 'Lady\\.', 'Countess\\.'])    \n",
    "    mr = '|'.join(['Mr\\.','Don\\.','Rev\\.','Dr\\.', 'Major\\.', 'Sir\\.', 'Col\\.', 'Capt\\.', 'Jonkheer\\.'])\n",
    "    miss = '|'.join(['Miss\\.', 'Mlle\\.'])\n",
    "    return df.assign(Name = lambda x : x['name'].str.replace('\\(.*\\)', '', regex=True),\n",
    "                     Mr =  lambda x : x['name'].str.contains(mr).astype(int) ,\n",
    "                     Miss = lambda x : x['name'].str.contains(miss).astype(int),\n",
    "                     Mrs = lambda x : x['name'].str.contains(mrs).astype(int),\n",
    "                     Master = lambda x : (x['name'].str.find('Master.') > -1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_egneenering(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    df = (df.assign(family_size = df.sibsp + df.parch+1,\n",
    "                    is_alone = lambda x: x.family_size < 2,\n",
    "                    calc_fare = lambda x: x.fare/x.family_size)\n",
    "            .astype({'is_alone':int})\n",
    "           )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    df = (pd.read_csv(file, dtype = {\n",
    "                            \"PassengerId\":np.int32,\n",
    "                            \"Name\": \"object\",\n",
    "                            \"Pclass\":np.int,\n",
    "                            \"Survived\":np.int32,\n",
    "                            \"Sex\":\"object\",\n",
    "                            \"Age\":np.float,\n",
    "                            \"SibSp\":np.int,\n",
    "                            \"Embarked\":\"object\",\n",
    "                            \"Cabin\":\"object\",\n",
    "                            \"Fare\":np.float64,\n",
    "                        },)\n",
    "            .rename(columns=str.lower)\n",
    "            .set_index(\"passengerid\")\n",
    "            .pipe(onehot_name)\n",
    "            .pipe(feature_egneenering)\n",
    "            .rename(columns=str.lower)\n",
    "            .drop(['cabin','name','ticket'],axis=1)\n",
    "        )\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/train.csv\"\n",
    "data = read_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['survived'],axis=1) \n",
    "y_train = data.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass           int64\n",
       "sex             object\n",
       "age            float64\n",
       "sibsp            int64\n",
       "parch            int64\n",
       "fare           float64\n",
       "embarked        object\n",
       "mr               int64\n",
       "miss             int64\n",
       "mrs              int64\n",
       "master           int64\n",
       "family_size      int64\n",
       "is_alone         int64\n",
       "calc_fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pclass', 'age', 'sibsp', 'parch', 'fare', 'mr', 'miss', 'mrs',\n",
       "       'master', 'family_size', 'is_alone', 'calc_fare'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengerid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sex embarked\n",
       "passengerid                 \n",
       "1              male        S\n",
       "2            female        C\n",
       "3            female        S\n",
       "4            female        S\n",
       "5              male        S\n",
       "...             ...      ...\n",
       "887            male        S\n",
       "888          female        S\n",
       "889          female        S\n",
       "890            male        C\n",
       "891            male        Q\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.select_dtypes('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = X_train.select_dtypes(exclude = 'O').columns.values #['age','fare','mr', 'miss', 'mrs', 'master']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(random_state=0,initial_strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include = 'O').columns.values#['Embarked', 'Sex', 'Pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent',missing_values=np.nan)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='error', drop=\"first\"))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_params(string0,string1,string2,string3=None):\n",
    "    params = []\n",
    "    if string3:\n",
    "        for el2 in string3[1]:\n",
    "            for el in string2[1]:\n",
    "                params.append({string1[0]:string1[1],\n",
    "                              string0[0]+'__'+string2[0]:[el],\n",
    "                              string0[1]+'__estimator__'+string2[0]:[el],\n",
    "                              string0[0]+'__'+string3[0]:[el2],\n",
    "                              string0[1]+'__estimator__'+string3[0]:[el2]})\n",
    "    else:\n",
    "        for el in string2[1]:\n",
    "            params.append({string1[0]:string1[1],\n",
    "                         string0[0]+'__'+string2[0]:[el],\n",
    "                         string0[1]+'__estimator__'+string2[0]:[el]})\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_feat = X_train.shape[1]\n",
    "\n",
    "#cross validation for inner and outer loopn in nested cv\n",
    "cv_outer = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_inner = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_sfs = StratifiedKFold(shuffle=True, random_state = rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RFR\n",
    "est = RandomForestClassifier(n_estimators=10,random_state=rs)\n",
    "sfs1 = SFS(estimator=est, \n",
    "           k_features=3,\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           scoring='neg_mean_absolute_error',\n",
    "           cv=cv_sfs)\n",
    "\n",
    "pipe_rfr_sfs = Pipeline([('pre_pros',  preprocessor),\n",
    "                 ('sfs', sfs1),\n",
    "                 ('rfc',est)])\n",
    "\n",
    "string1 = ['sfs__k_features', [(2,no_feat)]]\n",
    "string2 = ['n_estimators',list(range(1,10))]#[1,5,10,50,100,250,500,]]\n",
    "string3 = ['max_depth',list(range(1,10))]#[2,5,10,20,50,75,150]]\n",
    "param_grid_rfr_sfs = make_params(['rfc','sfs'],string1,string2,string3)\n",
    "\n",
    "gs_rf_sfs = GridSearchCV(estimator = pipe_rfr_sfs,\n",
    "                  param_grid = param_grid_rfr_sfs,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 32.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 327 ms, total: 11.8 s\n",
      "Wall time: 32min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pre_pros',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None...\n",
       "                         {'rfc__max_depth': [4], 'rfc__n_estimators': [2],\n",
       "                          'sfs__estimator__max_depth': [4],\n",
       "                          'sfs__estimator__n_estimators': [2],\n",
       "                          'sfs__k_features': [(2, 14)]},\n",
       "                         {'rfc__max_depth': [4], 'rfc__n_estimators': [3],\n",
       "                          'sfs__estimator__max_depth': [4],\n",
       "                          'sfs__estimator__n_estimators': [3],\n",
       "                          'sfs__k_features': [(2, 14)]}, ...],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_rf_sfs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8271734354403364"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_sfs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 5,\n",
       " 'rfc__n_estimators': 9,\n",
       " 'sfs__estimator__max_depth': 5,\n",
       " 'sfs__estimator__n_estimators': 9,\n",
       " 'sfs__k_features': (2, 14)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_sfs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: fine_tuned_rf_sfs.csv\n"
     ]
    }
   ],
   "source": [
    "submit(gs_rf_sfs.best_estimator_,'fine_tuned_rf_sfs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 5,\n",
       " 'rfc__n_estimators': 1,\n",
       " 'sfs__estimator__max_depth': 5,\n",
       " 'sfs__estimator__n_estimators': 1,\n",
       " 'sfs__k_features': (2, 14)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_sfs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model,filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    X_test = read_data(\"../data/test.csv\")\n",
    "    predictions = model.predict(X_test)\n",
    "    submission = pd.DataFrame({'PassengerId':X_test.index,'Survived':predictions})\n",
    "    submission.to_csv(filename,index=False)\n",
    "    print('Saved file: ' + filename)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: new_features_rf_sfs.csv\n"
     ]
    }
   ],
   "source": [
    "submit(gs_rf_sfs.best_estimator_,\"new_features_rf_sfs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = read_data(\"../data/test.csv\")\n",
    "predictions = gs_rf_sfs.best_estimator_.predict(X_test)\n",
    "submission = pd.DataFrame({'PassengerId':X_test.index,'Survived':predictions})\n",
    "filename = 'rf_sfs_sub.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 4.17 s, total: 4min 38s\n",
      "Wall time: 19min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pre_pros',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None...\n",
       "                         {'rfc__max_depth': [20], 'rfc__n_estimators': [100],\n",
       "                          'sfs__estimator__max_depth': [20],\n",
       "                          'sfs__estimator__n_estimators': [100],\n",
       "                          'sfs__k_features': [(2, 11)]},\n",
       "                         {'rfc__max_depth': [20], 'rfc__n_estimators': [250],\n",
       "                          'sfs__estimator__max_depth': [20],\n",
       "                          'sfs__estimator__n_estimators': [250],\n",
       "                          'sfs__k_features': [(2, 11)]}, ...],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_rf_sfs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858602724248321"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf_sfs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe rfr\n",
    "pipe_rfr = Pipeline([(\"pre_pros\",preprocessor), \n",
    "                     (\"rfr\",RandomForestClassifier(n_estimators=10,random_state=rs)) ])\n",
    "params_rfr = {\"rfr__n_estimators\":[1,5,10,50,100,250,500,1000],\n",
    "              \"rfr__max_depth\":[2,5,10,20,50,75,150]}\n",
    "\n",
    "#pipe lr\n",
    "pipe_lr = Pipeline([('pre_pros',preprocessor),\n",
    "                     ('pca',PCA()),\n",
    "                     ('lr',LogisticRegression(random_state=rs))])\n",
    "params_lr = {'pca__n_components':[1,3,5],\n",
    "             'lr__C':[0.0001,0.001,0.1,1,10,100,1000]}\n",
    "\n",
    "#cross validation for inner and outer loopn in nested cv\n",
    "cv_outer = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_inner = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_sfs = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "\n",
    "# grid-search\n",
    "gs_rf = GridSearchCV(estimator = pipe_rfr,\n",
    "                  param_grid = params_rfr,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr,\n",
    "                  param_grid = params_lr,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dumb baseline 61.62%\n",
      "Accuracy for baseline 78.68%\n"
     ]
    }
   ],
   "source": [
    "# Dumb baseline\n",
    "avg_dumb_baseline = np.ones((y_train.shape))*np.rint(y_train.astype(int).mean())\n",
    "acc_dumb_baseline = (y_train==avg_dumb_baseline).sum()/len(y_train)\n",
    "\n",
    "#smarter baseline - women survives and men dies\n",
    "baseline_pred = X_train.Sex.map({'female':1,'male':0})\n",
    "acc_baseline = (y_train==baseline_pred).sum()/len(y_train)\n",
    "\n",
    "#print\n",
    "print(f'Accuracy for dumb baseline {acc_dumb_baseline*100:.2f}%')\n",
    "print(f'Accuracy for baseline {acc_baseline*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nested cross validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 26s, sys: 10.8 s, total: 12min 37s\n",
      "Wall time: 12min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nested_score_rfr = cross_val_score(gs_rf,X_train,y_train,\n",
    "                                 cv=cv_outer,\n",
    "                                 scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80446927, 0.83707865, 0.7752809 , 0.8258427 , 0.86516854])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score_rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 229 ms, total: 2.91 s\n",
      "Wall time: 41min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nested_score_lr = cross_val_score(gs_lr,X_train,y_train,\n",
    "                                 cv=cv_outer,\n",
    "                                 scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80446927, 0.78651685, 0.79213483, 0.76404494, 0.79775281])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe lr\n",
    "pipe_lr_k = Pipeline([('pre_pros',preprocessor),\n",
    "                     ('inc_spac',PolynomialFeatures()),\n",
    "                     ('pca',PCA()),\n",
    "                     ('lr',LogisticRegression(random_state=rs))])\n",
    "params_lr_k = {\n",
    "             'inc_spac__degree':[1,2,5,10],\n",
    "             'pca__n_components':[1,3,5],\n",
    "             'lr__C':[0.0001,0.001,0.1,1,10,100,1000]}\n",
    "\n",
    "#cross validation for inner and outer loopn in nested cv\n",
    "cv_outer = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "cv_inner = StratifiedKFold(shuffle=True, random_state = rs)\n",
    "\n",
    "# grid-search\n",
    "\n",
    "\n",
    "gs_lr_k = GridSearchCV(estimator = pipe_lr_k,\n",
    "                  param_grid = params_lr_k,\n",
    "                  cv = cv_inner,\n",
    "                  scoring = \"accuracy\",\n",
    "                  n_jobs=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nested_score_lr_k = cross_val_score(gs_lr_k,X_train,y_train,\n",
    "                                    cv=cv_outer,\n",
    "                                    scoring='accuracy',\n",
    "                                    verbose=2,\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pre_pros',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None...\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=1,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'lr__C': [0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
       "                         'pca__n_components': [1, 3, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumbission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = read_data(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Mr',\n",
       "       'Miss', 'Mrs', 'Master'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Mr',\n",
       "       'Miss', 'Mrs', 'Master'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gs_rf_sfs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction_baseline = X_test.Sex.map({'female':1,'male':0})\n",
    "baseline_sub = pd.DataFrame({'PassengerId':X_test.index,'Survived':prediction_baseline})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':X_test.index,'Survived':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: rf_sfs_sub.csv\n"
     ]
    }
   ],
   "source": [
    "filename = 'rf_sfs_sub.csv'\n",
    "\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_titanic]",
   "language": "python",
   "name": "conda-env-kaggle_titanic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
